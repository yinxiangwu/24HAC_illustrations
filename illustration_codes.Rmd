---
title: "Illustrations of ISM and CoDA for 24HAC data analysis"
author: Yinxiang Wu
output: pdf_document
---

```{r,setup,include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,include = FALSE)
```

```{r}
library(tableone)
library(dplyr)
library(ggtern)
library(robCompositions)
library(mgcv)
library(kableExtra)
library(gmodels)
```

```{r}
dat <- read.csv('example_dat.csv')
glimpse(dat)
# data contains 6 variables
# sex
# sit, stand, step, sleep, % of time spent on each behavior per day
# outcome is continuous
dat$sex <- factor(dat$sex, c('Male','Female'))
# convert percentages to hours
dat$sit_hrs <- dat$sit * 24
dat$stand_hrs <- dat$stand * 24
dat$step_hrs <- dat$step * 24
dat$sleep_hrs <- dat$sleep * 24
```

In this document, we illustrated and repeated the analysis we performed in our paper *Analysis of the 24-Hour Activity Cycle: An illustration examining the association with cognitive function in the Adult Changes in Thought (ACT) Study [arXiv submission pending]*, based on the hypothetical data.

The dataset contains a continuous outcome variable $y$, a categorical variable $sex$, and compositional variables for $sit$, $stand$, $step$, and $sleep$, each of which ranges from 0 to 1, and they sum to 1. The compositional variables were simulated from the distribution of the real data that were used in the paper. The continuous outcome was generated based on the model

$$y = -0.04z_1 -0.06z_2 + 0.68z_3 + 0.5sex + \epsilon$$
where $z_1$, $z_2$, $z_3$ are a set of isometric log-ratio (ilr) coordinates of the compositional variables (see below), and $\epsilon \sim N(0, 0.25)$. For more details of the ilr-coordinates, please refer to the CoDA section below and see the section 3.2 in the paper.

$$z_1 = \sqrt{\frac{3}{4}}ln(\frac{Sit}{(Stand\times Step\times Sleep)^{\frac{1}{3}}})$$
$$z2 = \sqrt{\frac{2}{3}}ln(\frac{Stand}{(Step\times Sleep)^{\frac{1}{2}}})$$
$$z_3 = \sqrt{\frac{1}{2}}ln\frac{Step}{Sleep}$$

## Descriptive table of the data

The table 1 presents descriptive statistics of the sample.

```{r,include=TRUE}
tbl1 <- CreateTableOne(data = dat, vars = c('sex', 'sit_hrs','stand_hrs','step_hrs','sleep_hrs')) %>% print(., printToggle = FALSE)
rownames(tbl1)[3:6] <- c('Sit (hrs/day), mean (SD)', 'Stand (hrs/day), mean (SD)',
                         'Step (hrs/day), mean (SD)','Sleep (hrs/day), mean (SD)')
kable(tbl1, format = 'latex', align = 'c', vline = '',
      booktabs = TRUE,
      caption = "Descriptive statistics of the sample",
      linesep = '') %>%
  kable_styling(latex_options = "hold_position")
```

## ISM approach

### Linear ISM

Consider an example where each minute of the 24-hour day is classified into one of four activities: sleeping, sitting, standing, and stepping. The ISM is formulated by including the total activity and all but one of the activity variables – the activity you will explore displacing – in the model.  For example, with a continuous health outcome an ISM that leaves out the time stepping can be formulated, as below:

$$E(Y) = \beta_0 + \beta_1Sit + \beta_2 Stand + \beta_3 Step + \beta_4 Ttoal + \gamma Sex$$

where $E(Y)$ abbreviates the conditional mean of the health outcome given the time allocation variables (Sit, Stand, Sleep, Total measured on the same unit, e.g., hours in a 24-hour day), and the covariate sex. When *Total* is exactly a constant 24 hours/day for every subject, like in this hypothetical example, only one of the intercept or the Total terms can be included in the model. For more details, you can refer to the section 3.1 in the paper.

Four linear ISMs adjusted for sex were fit to the data, with each of the four activities omitted from the model one at a time. Table 2 summarizes the coefficient estimates. This is a table similar to the Table 2 in the paper.


```{r}
m_iso1 <- lm(outcome ~ sit_hrs + stand_hrs + sleep_hrs + sex, data = dat)
m_iso1_tab <- ShowRegTable(m_iso1,exp = FALSE,digits = 2)
m_iso1_tab <- rbind(m_iso1_tab[2:3,],c('Dropped','Dropped'),m_iso1_tab[4,])

m_iso2 <- lm(outcome ~ sit_hrs + step_hrs + sleep_hrs + sex, data = dat)
m_iso2_tab <- ShowRegTable(m_iso2,exp = FALSE,digits = 2)
m_iso2_tab <- rbind(m_iso2_tab[2,],c('Dropped','Dropped'),m_iso2_tab[3:4,])

m_iso3 <- lm(outcome ~  stand_hrs + step_hrs + sleep_hrs + sex, data = dat)
m_iso3_tab <- ShowRegTable(m_iso3,exp = FALSE,digits = 2)
m_iso3_tab <- rbind(c('Dropped','Dropped'),m_iso3_tab[2:4,])

m_iso4 <- lm(outcome ~ sit_hrs + stand_hrs + step_hrs + sex, data = dat)
m_iso4_tab <- ShowRegTable(m_iso4,exp = FALSE,digits = 2)
m_iso4_tab <- rbind(m_iso4_tab[2:4,],c('Dropped','Dropped'))
```

```{r,include=TRUE}
iso_tab <- cbind(m_iso3_tab,m_iso2_tab,m_iso1_tab, m_iso4_tab)
rownames(iso_tab) <- c('Sit (hours)','Stand (hours)','Step (hours)','Sleep (hours)')
colnames(iso_tab) <- rep(c('Beta (95\\% C.I.)','p-value'),4)
kable(iso_tab, format = 'latex',caption = 'Isotemporal Substitution of Activities, per 1 hr/Day Increase',escape = FALSE,booktabs = TRUE) %>% 
  add_header_above(c(' ' = 1,'Model with sit dropped' = 2, 'Model with stand dropped' = 2, 'Model with step dropped'=2, 'Model with sleep dropped' = 2),bold = TRUE) %>%
  kable_styling(latex_options = c('hold_position','scale_down','striped'))
#write.csv(t(iso_tab),'MS tables figures/ISM_table.csv')
```

The associations of 1-hr time reallocations between any two types of activity are summarized in Table 2. 
For example, the ISM model with Step dropped suggested that reallocating 1 hr/day from sitting, standing, or sleeping to stepping was associated with 0.35 [0.30, 0.40], 0.35 [0.29, 0.42], and 0.40 [0.35, 0.45] units higher mean (95% CI) outcome, respectively.


### Nonlinear ISM

A more flexible ISM could be fit with each activity term modeled by a penalized spline function, while keeping the total activity as a linear term. The slope of a spline term represents the instantaneous effect of increasing a small amount of time in the activity the spline term corresponds to, while decreasing the same small amount of time in the activity that is left out from the model. The optimal trade-off between smoothness and goodness of fit can be determined by either performing cross validation or minimizing the generalized cross validation (GCV) criteria. The significance of the association for each behavior in the nonlinear ISM model can be tested via a Wald like test [Wood SN 2006]. The nonlinear ISM analysis can be done in R with package “mgcv”.

For example, we fit a nonlinear ISM dropping step time adjusted for sex. The estimated smoothing terms for sit, stand, step are shown below. At the mean composition, all the smoothing terms equal to 0 because of the identifiablility constrain. We observed that increasing time in each of the behavior was associated with worse mean outcome, and in the main range of the data, the associations were approximately linear. This shows consistent results to that obtained from linear ISMs, and indicates that linear ISM would fit the data equally well and could be a better option for this hypothetical data because of its parsimony.

```{r, echo = FALSE, include = TRUE,fig.height=8,fig.width=8}
m_iso_nl <- gam(outcome ~ s(sit_hrs,bs = 'bs',k = 5) + s(stand_hrs,bs = 'bs',k = 5) + s(sleep_hrs,bs = 'bs', k = 5) + sex, data = dat)
# Total is the same for every subject and hence not included
par(mfrow = c(2,2))
plot(m_iso_nl)
```
\pagebreak

## CoDA

Unlike ISM treating each activity behavior as an univariate variable on the original time scale, the fundamental unit of observation is the multivariate vector of the proportions or percentages of the 24 hours that are spent in each type of activity.

Visualizations and compositional descriptive statistics of 24HAC can be helpful, before fitting any models. The Figure below (similar to the Figure 1 in the paper) displays 24HAC compositions of sit, stand, step, and sleep for the fake data using ternary diagrams, a common tool to visualize composition with 3 parts. Since the 24HAC of interest here consists of four activity behaviors, we plotted four ternary diagrams (A-D below), with each graph representing a sub-composition of three activity behaviors.  From the figure below, we can see how sub-compositions are distributed and possibly associated with the outcome.

### Simplex plot

```{r, include = TRUE, fig.height= 14, fig.width=16}
g1 <- ggtern(data = dat, aes(x = sit, y = stand, z = step,value = outcome)) + 
  geom_point(alpha = 1, aes(color = outcome)) +
  geom_point(data = dat[200,],color = 'black', size = 1.5) +
  geom_crosshair_tern(data = dat[200,], lty = 2, size = 1) +
  annotate(geom  = 'text',
                x     = 0.65,
                y     = 1 - 0.65,
                z     = 0,
                vjust = c(-0.5),
                hjust = c(0.35),
                angle = c(-0),
                label = paste("Sit=65%")) +
  annotate(geom  = 'text',
           x     = 0,
           y     = 0.26,
           z     = 1-0.26,
           vjust = c(1.25),
           hjust = c(-0.2),
           angle = c(0),
           label = paste("Stand=26%")) +
  annotate(geom  = 'text',
           x     = 1-0.08, 
           y     = 0,
           z     = 0.08,
           vjust = c(3),
           hjust = c(0.7),
           label = paste("Step=8%")) + 
  scale_colour_gradient2(midpoint=0,low="dodgerblue3",mid="lightgrey",high="darkorange")+
  theme_rgbw(base_size = 19) + 
  theme_nomask() +
  theme(legend.position = 'left',
        axis.title = element_text(size = 13))+
  labs(title = '(A)',Tarrow = "% Stand",Larrow = "% Sit",Rarrow = "% Step")
g2 <- ggtern(data = dat, aes(x = sit, y = stand, z = sleep,value = outcome)) + 
  geom_point(alpha = 1,aes(color = outcome)) +
  scale_colour_gradient2(midpoint=0,low="dodgerblue3",mid="lightgrey",high="darkorange")+
  theme_rgbw(base_size = 19)+
  labs(title = '(B)',Tarrow = "% Stand",Larrow = "% Sit",Rarrow = "% Sleep") + 
  theme(legend.position = 'none',
        axis.title = element_text(size = 13))

g3 <- ggtern(data = dat, aes(x = sit, y = sleep, z = step,value = outcome)) + 
  geom_point(alpha = 1,aes(color = outcome)) +
  scale_colour_gradient2(midpoint=0,low="dodgerblue3",mid="lightgrey",high="darkorange")+
  theme_rgbw(base_size = 19)+
  labs(title = '(C)',Tarrow = "% Sleep",Larrow = "% Sit",Rarrow = "% Step")+
  theme(legend.position = 'none',
        axis.title = element_text(size = 13))

g4 <- ggtern(data = dat, aes(x = sleep, y = stand, z = step,value = outcome)) + 
  geom_point(alpha = 1,aes(color = outcome)) +
  scale_colour_gradient2(midpoint=0,low="dodgerblue3",mid="lightgrey",high="darkorange")+
  theme_rgbw(base_size = 19)+
  labs(title = '(D)',Tarrow = "% Stand",Larrow = "% Sleep",Rarrow = "% Step") + 
  theme(legend.position = 'none',
        axis.title = element_text(size = 13))

grid.arrange(g1,g2,g3,g4, ncol = 2,layout_matrix = matrix(c(1,1,1,2,3,4),nrow = 3))
```


### Comparisons of compositional means by groups

The compositional mean is a common descriptive statistics to describe central tendency of compositional data. It is defined as the vector of geometric means of each behavior, rescaled to sum to 1. Please refer to the Supplemental material A1 for more details about this definition.  Since the components of a composition are inter-correlated, it is not sensible to calculate the variance of a single component. In stead, a variation matrix for the log-ratio is used to describe the interdependence between every pair of behaviors i.e. each element of that matrix is the variance of log-ratio between two components. An off-diagonal value close to 0 means the two parts are highly proportional in the observed data. Both compositional mean and variation matrix can be easily coded in R.

For inferential analysis such as hypothesis testing and regressions, CoDA relies on the isometric log-ratio (ilr) transformation, which transforms each D-part composition to a unique D-1 vector on a new coordinate system where each new coordinate is a log-ratio which falls along the real line. For example, a possible transformation is as follows:

\begin{align*}
z_1 & = \sqrt{\frac{3}{4}}ln(\frac{Sit}{(Stand\times Step\times Sleep)^{\frac{1}{3}}}) \\
z2 & = \sqrt{\frac{2}{3}}ln(\frac{Stand}{(Step\times Sleep)^{\frac{1}{2}}}) \\
z_3 & = \sqrt{\frac{1}{2}}ln\frac{Step}{Sleep} \\
\end{align*}

In R, we used the function *pivotCoord()* from the package *robCompositions* for this transformation.

With transformed data ($z_1$, $z_2$, and $z_3$) and under normality assumptions, we performed James multivariate analysis of variance with unequal variances to test the difference in the compositional mean between sex. The James test was available in the R pacage *Compositional*.

The table below (similar to the Table S2 in the paper) presents the compositional means in the overall sample and the groups defined by sex. P-value = 0.348 indicating insufficient evidence to reject the null hypothesis that the compositional means are equal between males and females.

```{r, include=TRUE}
coda_mean <- function(x) {
  gm <- apply(x,2,function(x) exp(mean(log(x))))
  return(gm/sum(gm))
}

comp_subgroup_mean <- function(data, group, coda_var, includeNA = FALSE){
  
  data.org <- data
  data <- data[complete.cases(data[,group]),]
  N <- ifelse(includeNA, nrow(data.org), nrow(data))
  lvl <- levels(data[, group])
  d <- length(lvl)
  tmp.l <- vector(mode = 'list', length = d)
  for (i in 1:d) {
    ind <- data[,group] == lvl[i]
    n <- sum(ind)
    perc <- round(n/N*100,1)
    n.perc <- paste(n, '(', perc, '\\%)')
    tmp.mean <- coda_mean(data[ind, coda_var])
    tmp.text <- paste((tmp.mean*24) %>% round(.,2), '(', (tmp.mean*100) %>% round(.,1),'\\%)')
    tmp.l[[i]] <- c(lvl[i],n.perc,tmp.text,' ')
  }
  
  ina <- as.numeric(data[, group])
  k <- max(ina)
  trans.data <- pivotCoord(data[,coda_var]) %>% as.matrix()
  
  if (k == 2) {
    tmp.test <- Compositional::james(trans.data[ina == 1,], trans.data[ina == 2,], R = 1)$info
  }
  
  if (k > 2) {
    tmp.test <- Compositional::maovjames(trans.data, ina)
  }
  
  tmp.tbl <- rbind(c(group,rep(' ', 5), ifelse(tmp.test['p-value'] < 0.001, '<0.001', round(tmp.test['p-value'],3))),
                   tmp.l %>% Reduce(rbind,.))
  
  if (includeNA) {
     n.na <- sum(is.na(data.org[,group]))
     tmp.tbl <- rbind(tmp.tbl, c('NA',paste(n.na,'(',round(n.na/N*100,1),'\\%)'),rep(' ',5)))
  }
 
  return(tmp.tbl)
}
tbl_sex <- comp_subgroup_mean(dat,'sex', c('sit','stand','step','sleep'))
tbl_comp <- rbind(c("Overall", '1000 (100 \\%)', paste0(round(coda_mean(dat[,2:5])*24,1),' ( ',round(coda_mean(dat[,2:5])*100,1),'\\%)'), ''),tbl_sex)
tbl_comp[2,1] <- 'Sex'

kable(tbl_comp,row.names = FALSE,format = 'latex',col.names = c(' ','N (\\%)','Sit','Stand','Step','Sleep','P-value'),booktabs = TRUE, caption = 'Compositional mean in subgroups',escape = FALSE) %>% 
    add_indent(3:4) %>% 
    #column_spec(1, width = "23em") %>% 
    kable_styling(latex_options = c('scale_down','HOLD_position')) %>%
    footnote(general = 'p-value from multivariate analysis of variance on the isometric log-transformed time use variables without assuming equal variance across subgroups.',threeparttable = TRUE)
```

### CoDA regressions and interpretations

Next, we applied CoDA to estimate a type of time reallocation i.e. increasing time in one activity while simultaneously proportionally decreasing time in the other activities. To achieve this, it is convenient to create four sets of ilr-coordinates with each behavior in turn being singled out as the numerator in the pivot coordinate $z_1$. Four linear regression models were fit with the continuous outcome, and with the resulting ilr-coordinates ($z_1$, $z_2$, $z_3$) as predictors. Each regression model is adjusted for sex.

Table below (similar to the Table 3 in the paper) summarized regression coefficient estimates $\hat \beta_1$ for the four CoDA pivot coordinates, each of which quantifies the effect of increasing time in one behavior by a factor while simultaneously decreasing time in the other behaviors by another factor. To make meaningful interpretation of those $\hat \beta_1$ estimates, we need to consider a referent composition in order to inform what magnitude difference in $z_1$ is a meaningful difference. Suppose the compositional mean calculated over the entire sample is chosen as the referent composition, and we are interested in the effect of increasing step by a factor of $1+r$. Then, all the other components should simultaneously be decreased by another factor $1-s$ to maintain $z_2$ and $z_3$ constant. Some derivations show that the difference in the mean outcome for such a time reallocation equals to $\hat \beta_1 \sqrt{\frac{3}{4}}log(\frac{1+r}{1-r})$. We created a R function *comp_contrast* that can output the difference between any two compositions in terms of ilr-coordinates (using *pivotCoord* function from the package *robCompositions*). More specifically, with a fitted CoDA regression model with $z_1$, $z_2$, $z_3$ (from pivotCoord) as predictors and a given referent composition say $c_1$, to estimate the effect of a specific time reallocation, we only need to know the composition $c_2$ after such time reallocation, and enter $c_1$ and $c_2$ into the *comp_contrast* function, we can obtain the difference between the two compositions in terms of $z_1$, $z_2$, and $z_3$. The estimated effect of such time reallocation is then a linear combination of that difference with linear coefficients as $\hat \beta_1$, $\hat \beta_2$, and $\hat \beta_3$. Note that CoDA regression results should be the same regardless of the form of ilr-transformations i.e. which set of ilr-coordinates is used. 

```{r,include=TRUE}
partitionOrder <- c("sit","stand","step","sleep")    # Indicate order to split off components
CODA.data1     <- dat[,partitionOrder] 
ilr1           <- pivotCoord(CODA.data1,1)
ilr2           <- pivotCoord(CODA.data1,2)
ilr3           <- pivotCoord(CODA.data1,3)
ilr4           <- pivotCoord(CODA.data1,4)

regdat1    <- data.frame(ilr1, y = dat$outcome, dat$sex)    # Remove original compositional variables
regdat2    <- data.frame(ilr2, y = dat$outcome, dat$sex)    # Remove original compositional variables
regdat3    <- data.frame(ilr3, y = dat$outcome, dat$sex)    # Remove original compositional variables
regdat4    <- data.frame(ilr4, y = dat$outcome, dat$sex)    # Remove original compositional variables

m1 <- lm(y ~ ., data = regdat1)
m2 <- lm(y ~ ., data = regdat2)
m3 <- lm(y ~ ., data = regdat3)
m4 <- lm(y ~ ., data = regdat4)

tbl_m <- rbind(ShowRegTable(m1,exp = FALSE,printToggle = FALSE)[2,],
               ShowRegTable(m2,exp = FALSE,printToggle = FALSE)[2,],
               ShowRegTable(m3,exp = FALSE,printToggle = FALSE)[2,],
               ShowRegTable(m4,exp = FALSE,printToggle = FALSE)[2,])
rownames(tbl_m) <- c('Sit vs Remaining','Stand vs Remaining',
                     'Step vs Remaining', 'Sleep vs Remaining')
colnames(tbl_m) <- c('Estimate (95\\% C.I.)','P-value')

kable(tbl_m, format = 'latex',caption = 'Regression of pivot coordinates against the outcome. Analysis controlled for sex. Remaining = remaining behaviors',escape = FALSE,booktabs = TRUE) %>% 
  kable_styling(latex_options = c('hold_position'))
```

Based on the results in Table 4, we can see increasing time in step while proportionally decreasing time in the other activities is associated with higher mean outcome. In contrast, increasing time in sleep while proportionally decreasing time in the other activities is associated with lower mean outcome. More specifically, increasing 30 minsin step while proportionally decreasing time in the other behaviors is associated with 0.19 [0.17, 0.22] increase in the outcome. Increasing 30 mins in sleep while proportionally decreasing time in the other behaviors is associated with a decrease in mean outcome of 0.04 [0.03, 0.05].

The results can be visualized by using the package *codaredistlm* available on Github: [github.com/tystan/codaredistlm](https://github.com/tystan/codaredistlm). Please see the blow plots created by using the function *pred_df* and *plot_delta_comp*. The figure below is similar to Figure 2 in the paper.


```{r, include=FALSE}
# say we are interested in the effect of increasing step by 30 mins while simlutaneously decreasing the other activities proportional by a same factor, using the compositional mean in the overall sample as the referent composition.
dat_coda_mean <- coda_mean(dat[,2:5])
# In this case, we are going to increase step by a factor of (1+r) with r = 39.8% calculated as
r <- 0.5/24/dat_coda_mean[3]
# to make sure all activities still sum to 1, we need to decrease the other activities by the same factor s = 2.2%
s <- r * dat_coda_mean[3]/(1-dat_coda_mean[3])
# then the effect of this time reallocation is given by multiplying the 
sqrt(3/4) * log((1+r)/(1-s))

c1 <- dat_coda_mean
c2 <- dat_coda_mean * c(1-s,1-s,1+r,1-s) # this gives the composition after such a composition

comp_contrast <- function(c1, c2, pivotvar = 1) {
    trans_dat <- pivotCoord(rbind(c1,c2), pivotvar = pivotvar)
    return(round(trans_dat[2,] - trans_dat[1,],3))
}
comp_contrast(c1,c2,pivotvar = 3) # this implies the estimated effect of the time reallocation is 0.309 * \hat \beta_1

# get estimated effects based on m3
estimable(m3,c(0,0.309,0,0,0))

# say we are interested in the effect of increasing sleep by 30 mins while simlutaneously decreasing the other activities proportional by a same factor, using the compositional mean in the overall sample as the referent composition.
# In this case, we are going to increase sleep by a factor of (1+r) with r = 5.7% calculated as
r <- 0.5/24/dat_coda_mean[4]
# to make sure all activities still sum to 1, we need to decrease the other activities by the same factor s = 2.2%
s <- r * dat_coda_mean[4]/(1-dat_coda_mean[4])
# then the effect of this time reallocation is given by multiplying the 
sqrt(3/4) * log((1+r)/(1-s))

c1 <- dat_coda_mean
c2 <- dat_coda_mean * c(1-s,1-s,1-s,1+r) # this gives the composition after such a composition

comp_contrast(c1,c2,pivotvar = 4) # this implies the estimated effect of the time reallocation is 0.309 * \hat \beta_1

# get estimated effects based on m3
estimable(m4,c(0,0.077,0,0,0))
```

```{r, include=FALSE}
library(codaredistlm)
pred_df <- 
    predict_delta_comps(
        dataf = dat,
        y = "outcome",
        comps = c("sit", "stand", "step", "sleep"),
        covars = c('sex'),
        # careful deltas greater than 25 min in magnitude induce negative compositions
        # predict_delta_comps() will warn you about this :-)
        deltas =  seq(-40, 40, by = 5) / (24 * 60), 
        comparisons = "prop-realloc", # or try "one-v-one"
        alpha = 0.05
    )
```

```{r, include=TRUE}
plot_delta_comp(
    pred_df, # provide the returned object from predict_delta_comps()
    # x-axis can be converted from propotion of composition to meaningful units
    comp_total = 24 * 60, # minutes available in the composition
    units_lab = "min" # just a label for plotting
)
```

\pagebreak

We can use the same functions to estimate and visualize the effect of time-reallocation between any pair of behaviors, e.g. reallocate time only between step and sit. See the plot below (similar to Figure 3 in the paper).

```{r, include = FALSE}
pred_df <- 
    predict_delta_comps(
        dataf = dat,
        y = "outcome",
        comps = c("sit", "stand", "step", "sleep"),
        covars = c('sex'),
        # careful deltas greater than 25 min in magnitude induce negative compositions
        # predict_delta_comps() will warn you about this :-)
        deltas =  seq(-40, 40, by = 5) / (24 * 60),
        comparisons = "one-v-one", # or try "one-v-one"
        alpha = 0.05
    )
```

```{r, include = TRUE}

plot_delta_comp(
    pred_df, # provide the returned object from predict_delta_comps()
    # x-axis can be converted from propotion of composition to meaningful units
    comp_total = 24 * 60, # minutes available in the composition
    units_lab = "min" # just a label for plotting
)
```

## LPA

LPA is a more exploratory method used to identify distinct latent subgroups with respect to activity profiles based on observed 24HAC data. This analysis can be done in R using the package *tidyLPA* (https://cran.r-project.org/web/packages/tidyLPA/vignettes/Introduction_to_tidyLPA.html). Another objective of LPA is to analyze the potential correlates of latent profiles and the associations of the profiles with outcomes. However, this analysis requires specialized regression methods that account for class assignment uncertainty, which can be performed in either *Mplus* or *LatentGold*. Both are commercial software. To the best of our knowledge, those methods have not been implemented in any R package. To perform similar analysis as in our paper, please find the LatentGold syntax in the supplemental materials (A2.2) of our paper.

Here, we only performed LPA to identify latent subgroups based on the compositional variables $sit$, $stand$, $step$, and $sleep$, so-called profile indicators.

LPA assumes that the profile indicators follow a finite mixture of multivariate normal distributions with each latent subgroup having its own mean and possibly distinct variance-covariance structure. The key part in running LPA is to determine the best number of classes i.e. latent groups. Usually, a series of models with different number of latent classes are fit. The best model is selected based on the mix of several criteria e.g. fit statistics, statistical comparisons between models, smallest number of subjects assigned to a class, interpretability of the classes, etc.

A key feature of 24HAC data is the co-dependence between activity behaviors, which prevents us from applying LPA to all 24HAC variables because it will lead to a degenerate (rank-deficient) covariance matrix. Two possible solutions to consider are (1) apply LPA to the same ilr-transformed variables used in CoDA (see CoDA section) or (2) drop one activity behavior variable from the LPA. Here, we chose to drop sleep from LPA. See our paper for more discussions.

We fit a series of LPA models with the number of classes ranging from 2 to 6 and allowed both variances and covariances of profile indicator variables to differ across latent classes (most flexible models). The Table 5 below shows the fit statistics for fitted models. AIC, BIC, CAIC, SABIC are all statistics balancing the model fit and complexity of the model. The difference between them is how they weigh the two objectives. In our case, they respectively favor 4-class model, 3-class model, 3-class model, 3-class model. Based on the bootstrap likelihood ratio test (BLRT) comparing the model with k and k-1 classes, we have strong evidence that the 3-class model is better than the 2-class model, but the 4-class model is not better than the 3-class model. Thus, 3-class model is used as the final model. For most cases, the decision process may be more complicated than here, and may need to be based on a mix of criteria and sometimes subjective.

```{r}
library(tidyLPA)
suppressMessages(mod <- estimate_profiles(df = dat[,2:4],n_profiles = 2:6, models = 6))
tbl_lpa <- sapply(mod,function(x) {x$fit}) %>% t(.)
tbl_lpa[,3:17] <- round(tbl_lpa[,3:17],2)
tbl_lpa_to_present <- tbl_lpa[,c(2,3,4,6,7,10,11,15,18,12)]
rownames(tbl_lpa_to_present) <- c('2-class model','3-class model','4-class model','5-class model','6-class model')
```

```{r, include = TRUE}
kable(tbl_lpa_to_present,format = 'latex',caption = 'Fit statistics for latent profile models with 2-6 profiles',booktabs = TRUE,digits = 2) %>% 
  kable_styling(latex_options = c('hold_position','scale_down'))
```

Once we obtain the final model, we can get the probability of each subject belonging to different latent classes (a.k.a posterior probability of class membership). The figure below shows the distribution of four activities across the three classes after we assign every subject to the class with the highest probability (a.k.a modal assignment).

```{r, include = TRUE}
lpa_final <- estimate_profiles(df = dat[,2:4],n_profiles = 3, models = 6)
dat$Class <- recode(get_data(lpa_final)$Class,'1' = '3', '2' = '2', '3' =  '1') # re-order according to mean sit time
dat_to_plot <- reshape2::melt(dat[,c('Class','sit_hrs','stand_hrs','step_hrs','sleep_hrs')],id.vars = 'Class')
levels(dat_to_plot$variable) <- c('Sit','Stand','Step','Sleep')
ggplot(data = dat_to_plot, aes(x = variable, y = value, fill = Class)) +
  geom_boxplot() +
  scale_y_continuous(breaks = seq(0,18,by = 1),
                     sec.axis = sec_axis(~./24,name = "% of a day", breaks = seq(0,1,by = 0.1),labels =scales::percent)) + 
  labs(x = ' ', y = 'Hours/day') + 
  theme_light() +
  theme(legend.title = element_blank())
```

In most applications, after obtaining a model for latent classes, we are also interested how the latent classes are associated different covariates or health outcomes. Most studies in the literature simply assign every individual to the class with the highest posterior probability of class membership and treat that class assignments as known information to do further inferential analysis. However, this could lead to bias effects and underestimated SEs. In our paper, we discussed this issue and current approaches to dealing with that. Those approaches are currently only available in LatentGold and Mplus, but not in R, and hence not presented here.
